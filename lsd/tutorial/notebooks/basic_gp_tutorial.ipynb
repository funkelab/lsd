{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_gp_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTxDAmWqY6Hs"
      },
      "source": [
        "*  This is a basic tutorial which gives an introduction into how gunpowder is used for data loading, augmentation, training, and prediction\n",
        "\n",
        "*  Based on tutorial here: http://funkey.science/gunpowder/tutorial_simple_pipeline.html#a-minimal-pipeline\n",
        "\n",
        "*  For the gunpowder API, see here: http://funkey.science/gunpowder/api.html\n",
        "\n",
        "*  If you are familiar with gunpowder already, check out the affinities/lsd tutorials for training\n",
        "\n",
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions. Double click to expand/collapse\n",
        "\n",
        "*  Sometimes colab can be slow when training, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKlQ062WGMpj"
      },
      "source": [
        "# package/repo installation\n",
        "\n",
        "# packages\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install zarr \n",
        "\n",
        "# repos\n",
        "!pip install git+git://github.com/funkey/gunpowder.git\n",
        "!pip install git+git://github.com/funkelab/funlib.learn.torch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TrfgddDNE26"
      },
      "source": [
        "import gunpowder as gp\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet\n",
        "from skimage import data\n",
        "from skimage import filters\n",
        "from skimage.io import imread\n",
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txccj6d3N_no"
      },
      "source": [
        "# make sure we all see the same\n",
        "np.random.seed(19623)\n",
        "random.seed(19623)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK1NpZpaNs5B"
      },
      "source": [
        "raw_data = data.astronaut()\n",
        "plt.imshow(raw_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SMgJERFNz-l"
      },
      "source": [
        "print(raw_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV1Q7Gf0OGjv"
      },
      "source": [
        "# make the channels first\n",
        "raw_data_t = raw_data.transpose(2,0,1)\n",
        "print(raw_data_t.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an5ecO0oOP8C"
      },
      "source": [
        "# create some dummy \"ground-truth\" to train on\n",
        "gt_data = filters.gaussian(raw_data_t[0], sigma=1.0) > 0.7\n",
        "gt_data = gt_data[np.newaxis,:].astype(np.float32)\n",
        "\n",
        "print(f\"raw shape: {raw_data_t.shape}\")\n",
        "print(f\"gt shape: {gt_data.shape}\")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax = axes.ravel()\n",
        "ax[0].imshow(raw_data)\n",
        "ax[1].imshow(gt_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8xs4XXROWP4"
      },
      "source": [
        "# create output zarr container\n",
        "f = zarr.open('sample_data.zarr', 'w')\n",
        "\n",
        "# write data into zarr container (two datasets - raw and ground truth)\n",
        "f['raw'] = raw_data_t\n",
        "f['ground_truth'] = gt_data\n",
        "\n",
        "# set an arbitrary resolution\n",
        "f['raw'].attrs['resolution'] = (1, 1)\n",
        "f['ground_truth'].attrs['resolution'] = (1, 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixSqvCAnPU6q",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view a batch\n",
        "\n",
        "# helper function to show image(s), channels first\n",
        "def imshow(raw=None, ground_truth=None, prediction=None, h=None, draw_box=None):\n",
        "    rows = 0\n",
        "    if raw is not None:\n",
        "        rows += 1\n",
        "        cols = raw.shape[0] if len(raw.shape) > 3 else 1\n",
        "    if ground_truth is not None:\n",
        "        rows += 1\n",
        "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 3 else 1\n",
        "    if prediction is not None:\n",
        "        rows += 1\n",
        "        cols = prediction.shape[0] if len(prediction.shape) > 3 else 1\n",
        "    fig, axes = plt.subplots(\n",
        "        rows,\n",
        "        cols,\n",
        "        figsize=(10, 4),\n",
        "        sharex=True,\n",
        "        sharey=True,\n",
        "        squeeze=False\n",
        "    )\n",
        "    if h is not None:\n",
        "        fig.subplots_adjust(hspace=h)\n",
        "    \n",
        "    if draw_box:\n",
        "        box = patches.Rectangle(\n",
        "                (draw_box[0]),\n",
        "                draw_box[1],\n",
        "                draw_box[2],\n",
        "                linewidth=2,\n",
        "                edgecolor='r',\n",
        "                facecolor='none'\n",
        "        )\n",
        "\n",
        "        # Add the patch to the Axes\n",
        "        axes[0][0].add_patch(box)\n",
        "    \n",
        "    def wrapper(\n",
        "        data,\n",
        "        row,\n",
        "        name=\"RAW\"):\n",
        "        \n",
        "        if len(data.shape) == 3:\n",
        "            if name == 'RAW':\n",
        "                axes[0][0].imshow(data.transpose(1,2,0))\n",
        "                axes[0][0].set_title(name)\n",
        "            else:\n",
        "                axes[row][0].imshow(data[0])\n",
        "                axes[row][0].set_title(name)  \n",
        "            \n",
        "        else:\n",
        "            for i, im in enumerate(data):\n",
        "                if name == 'RAW':\n",
        "                    axes[0][i].imshow(im.transpose(1, 2, 0))\n",
        "                    axes[0][i].set_title(name)\n",
        "                else:\n",
        "                    axes[row][i].imshow(im[0])\n",
        "                    axes[row][i].set_title(name)\n",
        "    \n",
        "    row=0\n",
        "        \n",
        "    if raw is not None:\n",
        "        wrapper(raw,row=row)\n",
        "        row += 1\n",
        "    if ground_truth is not None:\n",
        "        wrapper(ground_truth,row=row,name='GROUND TRUTH')\n",
        "        row += 1\n",
        "    if prediction is not None:\n",
        "        wrapper(prediction,row=row,name='PREDICTION')\n",
        "        row += 1\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBAmVzLHPkAR"
      },
      "source": [
        "# same data, just in zarr\n",
        "imshow(raw=zarr.open('sample_data.zarr')['raw'][:])\n",
        "imshow(ground_truth=zarr.open('sample_data.zarr')['ground_truth'][:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVqWKuk8Pnag"
      },
      "source": [
        "# declare arrays to use in the pipeline\n",
        "raw = gp.ArrayKey('RAW')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T30o1E3IPqEd"
      },
      "source": [
        "# create \"pipeline\" consisting only of a data source\n",
        "source = gp.ZarrSource(\n",
        "    'sample_data.zarr',  # the zarr container\n",
        "    {raw: 'raw'},  # which dataset to associate to the array key\n",
        "    {raw: gp.ArraySpec(interpolatable=True)}  # meta-information\n",
        ")\n",
        "pipeline = source\n",
        "\n",
        "print(pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmipblIXPx3W"
      },
      "source": [
        "# formulate a request for \"raw\" (start at zero with a size of 64)\n",
        "request = gp.BatchRequest()\n",
        "request_roi = gp.Roi((0, 0), (64, 64))\n",
        "request[raw] = request_roi"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aM9y5z7PzZk"
      },
      "source": [
        "# build the pipeline...\n",
        "with gp.build(pipeline):\n",
        "\n",
        "  # ...and request a batch\n",
        "  batch = pipeline.request_batch(request)\n",
        "\n",
        "# show the content of the batch\n",
        "print(f\"batch returned: {batch}\")\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjhVqqgrP2yH"
      },
      "source": [
        "print(request[raw].roi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gkjZ77nP42h"
      },
      "source": [
        "print(f\"offset: {request[raw].roi.get_begin()}\")\n",
        "print(f\"shape: {request[raw].roi.get_shape()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTiCb00OP6hY"
      },
      "source": [
        "# location context\n",
        "imshow(raw=batch[raw].data)\n",
        "\n",
        "imshow(\n",
        "    raw=zarr.open('sample_data.zarr')['raw'][:],\n",
        "    draw_box=(\n",
        "        request[raw].roi.get_begin()[::-1],\n",
        "        request[raw].roi.get_shape()[0],\n",
        "        request[raw].roi.get_shape()[1]\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRciyeVzP89p"
      },
      "source": [
        "# change the offset of the request from (0, 0) --> (50, 150)\n",
        "request[raw] = gp.Roi((50, 150), (64, 64))\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "print(f\"batch returned: {batch}\")\n",
        "imshow(batch[raw].data)\n",
        "\n",
        "imshow(\n",
        "    raw=zarr.open('sample_data.zarr')['raw'][:],\n",
        "    draw_box=(\n",
        "        request[raw].roi.get_begin()[::-1],\n",
        "        request[raw].roi.get_shape()[0],\n",
        "        request[raw].roi.get_shape()[1]\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4EyLOA5QA_f"
      },
      "source": [
        "# add a RandomLocation node to randomly select a sample\n",
        "\n",
        "random_location = gp.RandomLocation()\n",
        "pipeline = source + random_location\n",
        "\n",
        "print(pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSDA5io6QJeg"
      },
      "source": [
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o92HGX2NQLIN"
      },
      "source": [
        "# add a node to randomly mirror / transpose a batch\n",
        "simple_augment = gp.SimpleAugment()\n",
        "pipeline = source + random_location + simple_augment\n",
        "\n",
        "print(pipeline)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep-Iz-YOQM30"
      },
      "source": [
        "# create a larger request roi\n",
        "request[raw] = gp.Roi((0, 0), (64, 128))\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDjGfjgjQPDC"
      },
      "source": [
        "# elastically deform a batch\n",
        "elastic_augment = gp.ElasticAugment(\n",
        "  control_point_spacing=(16, 16),\n",
        "  jitter_sigma=(4.0, 4.0),\n",
        "  rotation_interval=(0, math.pi/2))\n",
        "pipeline = source + random_location + simple_augment + elastic_augment\n",
        "\n",
        "print(pipeline)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jEKGuIDQWCi"
      },
      "source": [
        "# normalize values to floats between 0 and 1\n",
        "normalize = gp.Normalize(raw)\n",
        "\n",
        "# augment the intensity of a batch\n",
        "intensity_augment = gp.IntensityAugment(\n",
        "  raw,\n",
        "  scale_min=0.8,\n",
        "  scale_max=1.2,\n",
        "  shift_min=-0.2,\n",
        "  shift_max=0.2)\n",
        "\n",
        "# add random noise\n",
        "noise_augment = gp.NoiseAugment(raw)\n",
        "\n",
        "# build pipeline\n",
        "pipeline = (\n",
        "  source +\n",
        "  normalize +\n",
        "  random_location +\n",
        "  simple_augment +\n",
        "  elastic_augment +\n",
        "  intensity_augment +\n",
        "  noise_augment)\n",
        "\n",
        "print(pipeline)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0bXHciQYdg"
      },
      "source": [
        "# create a batch with 5 samples\n",
        "stack = gp.Stack(5)\n",
        "\n",
        "pipeline = (\n",
        "  source +\n",
        "  normalize +\n",
        "  random_location +\n",
        "  simple_augment +\n",
        "  elastic_augment +\n",
        "  intensity_augment +\n",
        "  noise_augment +\n",
        "  stack)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaZZPsbeQain"
      },
      "source": [
        "# request multiple arrays (i.e raw and ground truth)\n",
        "\n",
        "# first create an array key for the ground truth\n",
        "gt = gp.ArrayKey('GROUND_TRUTH')\n",
        "\n",
        "# load both data sources\n",
        "source = gp.ZarrSource(\n",
        "    'sample_data.zarr', # zarr container\n",
        "    {\n",
        "      raw: 'raw', # raw dataset\n",
        "      gt: 'ground_truth' # ground truth dataset\n",
        "    },\n",
        "    {\n",
        "      raw: gp.ArraySpec(interpolatable=True),\n",
        "      gt: gp.ArraySpec(interpolatable=False)\n",
        "    })\n",
        "\n",
        "# create ground truth request roi (same as raw)\n",
        "request[gt] = gp.Roi((0, 0), (64, 128))\n",
        "\n",
        "pipeline = (\n",
        "  source +\n",
        "  normalize +\n",
        "  random_location +\n",
        "  simple_augment +\n",
        "  elastic_augment +\n",
        "  intensity_augment +\n",
        "  noise_augment +\n",
        "  stack)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "imshow(raw=batch[raw].data, ground_truth=batch[gt].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHtNMO13QehI"
      },
      "source": [
        "# make sure we all see the same\n",
        "torch.manual_seed(18)\n",
        "\n",
        "# create a basic 2D U-Net mapping from 3 input channels (rgb)\n",
        "# to one output channel (segmentation - binary in this case)\n",
        "unet = UNet(\n",
        "  in_channels=3,\n",
        "  num_fmaps=4,\n",
        "  fmap_inc_factor=2,\n",
        "  downsample_factors=[[2, 2], [2, 2]],\n",
        "  kernel_size_down=[[[3, 3], [3, 3]]]*3,\n",
        "  kernel_size_up=[[[3, 3], [3, 3]]]*2,\n",
        "  num_fmaps_out=1,\n",
        "  padding='same')\n",
        "\n",
        "# pass through sigmoid to ensure output values between 0 & 1\n",
        "model = torch.nn.Sequential(unet, torch.nn.Sigmoid())\n",
        "\n",
        "# add loss and optimizer\n",
        "loss = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6Hb35pIQiRH"
      },
      "source": [
        "# create new array key for the network output\n",
        "prediction = gp.ArrayKey('PREDICTION')\n",
        "\n",
        "# ensure model is in train mode\n",
        "model.train()\n",
        "\n",
        "# create a train node using our model, loss, and optimizer\n",
        "train = gp.torch.Train(\n",
        "  model,\n",
        "  loss,\n",
        "  optimizer,\n",
        "  inputs = {\n",
        "    'input': raw\n",
        "  },\n",
        "  loss_inputs = {\n",
        "    0: prediction,\n",
        "    1: gt\n",
        "  },\n",
        "  outputs = {\n",
        "    0: prediction\n",
        "  },\n",
        "  save_every=100\n",
        ")\n",
        "\n",
        "train_pipeline = (\n",
        "  source +\n",
        "  normalize +\n",
        "  random_location +\n",
        "  simple_augment +\n",
        "  elastic_augment +\n",
        "  intensity_augment +\n",
        "  noise_augment +\n",
        "  stack +\n",
        "  train)\n",
        "\n",
        "# add the prediction to the request\n",
        "request[prediction] = gp.Roi((0, 0), (64, 128))\n",
        "\n",
        "with gp.build(train_pipeline):\n",
        "    batch = train_pipeline.request_batch(request)\n",
        "\n",
        "imshow(\n",
        "    raw=batch[raw].data,\n",
        "    ground_truth=batch[gt].data,\n",
        "    prediction=batch[prediction].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q9f9XpsQkdj"
      },
      "source": [
        "# train for a few more iterations\n",
        "iterations = 100\n",
        "with gp.build(train_pipeline):\n",
        "    progress = tqdm(range(iterations))\n",
        "    for i in progress:\n",
        "        batch = train_pipeline.request_batch(request)\n",
        "        progress.set_description(f'Training iteration {i}') \n",
        "        pass\n",
        "\n",
        "imshow(\n",
        "    raw=batch[raw].data,\n",
        "    ground_truth=batch[gt].data,\n",
        "    prediction=batch[prediction].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx8TNNAfQoAF"
      },
      "source": [
        "# set model into evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# create predict node\n",
        "predict = gp.torch.Predict(\n",
        "  model,\n",
        "  inputs = {\n",
        "    'input': raw\n",
        "  },\n",
        "  outputs = {\n",
        "    0: prediction\n",
        "  })\n",
        "\n",
        "# one sample to predict\n",
        "stack = gp.Stack(1)\n",
        "\n",
        "# request matching the model input and output sizes\n",
        "scan_request = gp.BatchRequest()\n",
        "scan_request[raw] = gp.Roi((0, 0), (64, 128))\n",
        "scan_request[prediction] = gp.Roi((0, 0), (64, 128))\n",
        "scan_request[gt] = gp.Roi((0, 0), (64, 128))\n",
        "\n",
        "# scan over target dataset using scan request chunk sizes\n",
        "scan = gp.Scan(scan_request)\n",
        "\n",
        "predict_pipeline = (\n",
        "  source +\n",
        "  normalize +\n",
        "  stack +\n",
        "  predict +\n",
        "  scan)\n",
        "\n",
        "# request for raw and prediction for the whole image (shape is 512, 512)\n",
        "predict_request = gp.BatchRequest()\n",
        "predict_request[raw] = gp.Roi((0, 0), (512, 512))\n",
        "predict_request[prediction] = gp.Roi((0, 0), (512, 512))\n",
        "predict_request[gt] = gp.Roi((0, 0), (512, 512))\n",
        "\n",
        "with gp.build(predict_pipeline):\n",
        "    batch = predict_pipeline.request_batch(predict_request)\n",
        "\n",
        "imshow(raw=batch[raw].data)\n",
        "imshow(ground_truth=batch[gt].data)\n",
        "imshow(prediction=batch[prediction].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfac73j_Q_LL"
      },
      "source": [
        "# predictions aren't so good, lets train a little longer\n",
        "with gp.build(train_pipeline):\n",
        "    progress = tqdm(range(iterations*5))\n",
        "    for i in progress:\n",
        "        batch = train_pipeline.request_batch(request)\n",
        "        progress.set_description(f'Training iteration {iterations + i}')\n",
        "        pass\n",
        "\n",
        "imshow(batch[raw].data, batch[gt].data, batch[prediction].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN-EPudTRFOc"
      },
      "source": [
        "# predict again\n",
        "with gp.build(predict_pipeline):\n",
        "    batch = predict_pipeline.request_batch(predict_request)\n",
        "\n",
        "imshow(raw=batch[raw].data)\n",
        "imshow(ground_truth=batch[gt].data)\n",
        "imshow(prediction=batch[prediction].data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Sjjj7GMfFjp"
      },
      "source": [
        "*  Just a general idea of how to use gunpowder\n",
        "\n",
        "*  see how to train affinities in **train_affinities.ipynb**\n"
      ]
    }
  ]
}