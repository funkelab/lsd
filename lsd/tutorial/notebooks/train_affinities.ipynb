{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_affinities.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRnIelbpKeck"
      },
      "source": [
        "*  This tutorial goes over a basic 2d affinity network using gunpowder (http://funkey.science/gunpowder)\n",
        "\n",
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This tutorial follows the basic gunpowder tutorial, and is therefore condensed. Check out the basic gunpowder tutorial (**basic_gp_tutorial.ipynb**) if there is any confusion throughout\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  Sometimes colab can be slow when training, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAnmBl37zAO4",
        "cellView": "form"
      },
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install gunpowder\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install torch\n",
        "!pip install tqdm\n",
        "!pip install zarr \n",
        "\n",
        "# repos\n",
        "!pip install git+https://github.com/funkelab/funlib.learn.torch.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zOP2F0FsAVi",
        "cellView": "form"
      },
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from gunpowder.torch import Train\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1CtAERzN7E5",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDKVwwRqy5W-",
        "cellView": "form"
      },
      "source": [
        "#@title utility  function to download / save data as zarr\n",
        "\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  container = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for index, section in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {section}')\n",
        "\n",
        "    raw_slice = raw[section]\n",
        "    labels_slice = labels[section]\n",
        "\n",
        "    if squeeze:\n",
        "      raw_slice = np.squeeze(raw_slice)\n",
        "      labels_slice = np.squeeze(labels_slice)\n",
        "\n",
        "    for ds_name, data in [\n",
        "        ('raw', raw_slice),\n",
        "        ('labels', labels_slice)]:\n",
        "        \n",
        "        container[f'{ds_name}/{index}'] = data\n",
        "        container[f'{ds_name}/{index}'].attrs['offset'] = offset\n",
        "        container[f'{ds_name}/{index}'].attrs['resolution'] = resolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7EKVxk0qlG"
      },
      "source": [
        "#lets use the some cremi challenge data as an example, might take a few seconds to download\n",
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'training_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipkYaTCj2b0X"
      },
      "source": [
        "#view the first 5 sections of the volume\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            5,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "for i in range(5):\n",
        "  axes[0][i].imshow(zarr.open('training_data.zarr')[f'raw/{i}'][:], cmap='gray')\n",
        "  axes[0][i].imshow(create_lut(zarr.open('training_data.zarr')[f'labels/{i}'][:]), alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJi6CQToD-Ne"
      },
      "source": [
        "# and a random 5 sections...\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            5,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "rand = random.sample(range(0, 124), 5)\n",
        "\n",
        "for i,j in enumerate(rand):\n",
        "  axes[0][i].imshow(zarr.open('training_data.zarr')[f'raw/{j}'][:], cmap='gray')\n",
        "  axes[0][i].imshow(create_lut(zarr.open('training_data.zarr')[f'labels/{j}'][:]), alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRrmII40OFlJ",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view a batch\n",
        "\n",
        "def imshow(\n",
        "        raw=None,\n",
        "        ground_truth=None,\n",
        "        target=None,\n",
        "        prediction=None,\n",
        "        h=None,\n",
        "        shader='jet',\n",
        "        subplot=True):\n",
        "\n",
        "    rows = 0\n",
        "\n",
        "    if raw is not None:\n",
        "        rows += 1\n",
        "        cols = raw.shape[0] if len(raw.shape) > 2 else 1\n",
        "    if ground_truth is not None:\n",
        "        rows += 1\n",
        "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 2 else 1\n",
        "    if target is not None:\n",
        "        rows += 1\n",
        "        cols = target.shape[0] if len(target.shape) > 2 else 1\n",
        "    if prediction is not None:\n",
        "        rows += 1\n",
        "        cols = prediction.shape[0] if len(prediction.shape) > 2 else 1\n",
        "\n",
        "    if subplot:\n",
        "        fig, axes = plt.subplots(\n",
        "            rows,\n",
        "            cols,\n",
        "            figsize=(10, 4),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "    if h is not None:\n",
        "        fig.subplots_adjust(hspace=h)\n",
        "\n",
        "    def wrapper(data,row,name=\"raw\"):\n",
        "        \n",
        "        if subplot:\n",
        "            if len(data.shape) == 2:\n",
        "                if name == 'raw':\n",
        "                    axes[0][0].imshow(data, cmap='gray')\n",
        "                    axes[0][0].set_title(name)\n",
        "                else:\n",
        "                    axes[row][0].imshow(create_lut(data))\n",
        "                    axes[row][0].set_title(name)\n",
        "\n",
        "            elif len(data.shape) == 3:\n",
        "                for i, im in enumerate(data):\n",
        "                    if name == 'raw':\n",
        "                        axes[0][i].imshow(im, cmap='gray')\n",
        "                        axes[0][i].set_title(name)\n",
        "                    else:\n",
        "                        axes[row][i].imshow(create_lut(im))\n",
        "                        axes[row][i].set_title(name)\n",
        "                            \n",
        "            else:\n",
        "                for i, im in enumerate(data):\n",
        "                    axes[row][i].imshow(im[0] + im[1], cmap=shader)\n",
        "                    axes[row][i].set_title(name)\n",
        "\n",
        "        else:\n",
        "            if name == 'raw':\n",
        "                plt.imshow(data, cmap='gray')\n",
        "            if name == 'labels':\n",
        "                plt.imshow(data, alpha=0.5)\n",
        "\n",
        "    row=0 \n",
        "\n",
        "    if raw is not None:\n",
        "        wrapper(raw,row=row)\n",
        "        row += 1\n",
        "    if ground_truth is not None:\n",
        "        wrapper(ground_truth,row=row,name='labels')\n",
        "        row += 1\n",
        "    if target is not None:\n",
        "        wrapper(target,row=row,name='target')\n",
        "        row += 1\n",
        "    if prediction is not None:\n",
        "        wrapper(prediction,row=row,name='prediction')\n",
        "        row += 1\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGt6vpBSOK4F"
      },
      "source": [
        "# show 110th section of data using utility func\n",
        "\n",
        "imshow(raw=zarr.open('training_data.zarr')['raw/110'][:])\n",
        "imshow(ground_truth=zarr.open('training_data.zarr')['labels/110'][:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-IghvKxOOdc"
      },
      "source": [
        "# create gunpowder array keys\n",
        "\n",
        "raw = gp.ArrayKey('RAW')\n",
        "labels = gp.ArrayKey('LABELS')\n",
        "gt_affs = gp.ArrayKey('GT_AFFS')\n",
        "affs_weights = gp.ArrayKey('AFFS_WEIGHTS')\n",
        "pred_affs = gp.ArrayKey('PRED_AFFS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih0lYvqfOQ_v"
      },
      "source": [
        "# set voxel size\n",
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "# our network will have a smaller output shape than input shape\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "# convert sizes to world units (i.e nanometers)\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZGv6vpXOYHh"
      },
      "source": [
        "# load the first image as a datasource\n",
        "\n",
        "sources = gp.ZarrSource(\n",
        "    'training_data.zarr',  \n",
        "    {\n",
        "        raw: 'raw/0',\n",
        "        labels: 'labels/0'\n",
        "    },  \n",
        "    {\n",
        "        raw: gp.ArraySpec(interpolatable=True),\n",
        "        labels: gp.ArraySpec(interpolatable=False)\n",
        "    })\n",
        "\n",
        "# normalize raw data between 0 and 1\n",
        "sources += gp.Normalize(raw)\n",
        "\n",
        "# randomly select a patch of the batch shape from the data source \n",
        "sources += gp.RandomLocation()\n",
        "\n",
        "pipeline = sources\n",
        "\n",
        "print(pipeline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh_Vyb1QOblb"
      },
      "source": [
        "# create a batch request\n",
        "request = gp.BatchRequest()\n",
        "\n",
        "# for now let's just check raw data and labels data, and keep the requests the same size since we aren't training yet\n",
        "request.add(raw, input_size)\n",
        "request.add(labels, input_size)\n",
        "\n",
        "# three iterations\n",
        "for i in range(3):\n",
        "    with gp.build(pipeline):\n",
        "        batch = pipeline.request_batch(request)\n",
        "\n",
        "    print(f'BATCH {i} DATA')\n",
        "\n",
        "    imshow(\n",
        "        raw=np.squeeze(batch[raw].data),\n",
        "        ground_truth=batch[labels].data,\n",
        "        h=0.3)\n",
        "    \n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTmgDSCPg-3c"
      },
      "source": [
        "# same logic, but for multiple samples. will create a tuple of samples.\n",
        "# for each sample, normalize the raw data + randomly choose a location\n",
        "# each tuple entry represents: sample + normalize + random location\n",
        "\n",
        "num_samples = 5\n",
        "\n",
        "sources = tuple(\n",
        "    gp.ZarrSource(\n",
        "        'training_data.zarr',  \n",
        "        {\n",
        "            raw: f'raw/{i}',\n",
        "            labels: f'labels/{i}'\n",
        "        },  \n",
        "        {\n",
        "            raw: gp.ArraySpec(interpolatable=True),\n",
        "            labels: gp.ArraySpec(interpolatable=False)\n",
        "        }) + \n",
        "        gp.Normalize(raw) +\n",
        "        gp.RandomLocation()\n",
        "        for i in range(num_samples)\n",
        "    )\n",
        "\n",
        "print(sources)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "FWfSodLAOd81"
      },
      "source": [
        "# now lets get every available image and change our batch size\n",
        "num_samples = 124\n",
        "batch_size = 5\n",
        "\n",
        "sources = tuple(\n",
        "    gp.ZarrSource(\n",
        "        'training_data.zarr',  \n",
        "        {\n",
        "            raw: f'raw/{i}',\n",
        "            labels: f'labels/{i}'\n",
        "        },  \n",
        "        {\n",
        "            raw: gp.ArraySpec(interpolatable=True),\n",
        "            labels: gp.ArraySpec(interpolatable=False)\n",
        "        }) + \n",
        "        gp.Normalize(raw) +\n",
        "        gp.RandomLocation()\n",
        "        for i in range(num_samples)\n",
        "    )\n",
        "\n",
        "# our arrays currently have the following shapes:\n",
        "\n",
        "# raw: (h, w)\n",
        "# labels: (h, w)\n",
        "\n",
        "pipeline = sources\n",
        "\n",
        "# randomly choose a sample from our tuple of samples\n",
        "pipeline += gp.RandomProvider()\n",
        "\n",
        "# randomly mirror and transpose a batch\n",
        "pipeline += gp.SimpleAugment()\n",
        "\n",
        "# elastically deform the batch\n",
        "pipeline += gp.ElasticAugment(\n",
        "    control_point_spacing=(64, 64),\n",
        "    jitter_sigma=(5.0, 5.0),\n",
        "    rotation_interval=(0, math.pi/2))\n",
        "\n",
        "# randomly shift and scale intensities\n",
        "pipeline += gp.IntensityAugment(\n",
        "    raw,\n",
        "    scale_min=0.9,\n",
        "    scale_max=1.1,\n",
        "    shift_min=-0.1,\n",
        "    shift_max=0.1)\n",
        "\n",
        "# dilate the boundary between labels\n",
        "pipeline += gp.GrowBoundary(labels)\n",
        "\n",
        "# calculate ground truth affinities\n",
        "pipeline += gp.AddAffinities(\n",
        "    affinity_neighborhood=[\n",
        "        [0, -1],\n",
        "        [-1, 0]],\n",
        "    labels=labels,\n",
        "    affinities=gt_affs,\n",
        "    dtype=np.float32)\n",
        "\n",
        "# no longer need labels since we use the gt affs for training\n",
        "# our arrays currently have the following shapes:\n",
        "\n",
        "# raw: (h, w)\n",
        "# gt_affs: (2, h, w) --> 2 for channel dim because we have x & y affinities. \n",
        "\n",
        "# create scale array to balance class losses (will then use the affs_weights array during training)\n",
        "pipeline += gp.BalanceLabels(\n",
        "        gt_affs,\n",
        "        affs_weights)\n",
        "\n",
        "# pytorch requires tensors with shape (b,c,h,w) for 2d images\n",
        "\n",
        "# add channel dimension to raw array\n",
        "pipeline += gp.Unsqueeze([raw])\n",
        "\n",
        "# our arrays now have shapes:\n",
        "\n",
        "# raw: (1, h, w)\n",
        "# gt_affs: (2, h, w)\n",
        "# affs weights: (2, h, w)\n",
        "\n",
        "# add batch size\n",
        "pipeline += gp.Stack(batch_size)\n",
        "\n",
        "# our arrays now have shapes:\n",
        "\n",
        "# raw: (b, 1, h, w)\n",
        "# gt_affs: (b, 2, h, w)\n",
        "# affs weights: (b, 2, h, w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJLdw3O_Ot6Y"
      },
      "source": [
        "# create new request\n",
        "request = gp.BatchRequest()\n",
        "\n",
        "# we'll make our request sizes correct now to prepare for subsequent training\n",
        "\n",
        "# our raw data is our input so we need to request the input size\n",
        "request.add(raw, input_size)\n",
        "\n",
        "# all other arrays will need to be equal to the output size since our unet has a smaller output size than input size\n",
        "request.add(labels, output_size)\n",
        "request.add(gt_affs, output_size)\n",
        "request.add(affs_weights, output_size)\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    batch = pipeline.request_batch(request)\n",
        "\n",
        "# need to view the raw data in the same roi as labels data\n",
        "# this is just for matplotlib, so we don't see an offset\n",
        "\n",
        "start = request[labels].roi.get_begin()/voxel_size\n",
        "end = request[labels].roi.get_end()/voxel_size\n",
        "\n",
        "# each column will represent a batch for a single iteration \n",
        "    \n",
        "imshow(\n",
        "        raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]),\n",
        "        ground_truth=batch[labels].data,\n",
        "        target=batch[gt_affs].data,\n",
        "        h=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OURctIkOwbZ"
      },
      "source": [
        "# we can train now (example using pytorch)\n",
        "# first, create a custom MSE Loss with weighting\n",
        "\n",
        "class WeightedMSELoss(torch.nn.MSELoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(WeightedMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction, target, weights):\n",
        "\n",
        "        scaled = (weights * (prediction - target) ** 2)\n",
        "\n",
        "        if len(torch.nonzero(scaled)) != 0:\n",
        "\n",
        "            mask = torch.masked_select(scaled, torch.gt(weights, 0))\n",
        "            loss = torch.mean(mask)\n",
        "\n",
        "        else:\n",
        "            loss = torch.mean(scaled)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCoScUgIP-38"
      },
      "source": [
        "# number of input feature maps to the network (will also be number of output feature maps)\n",
        "num_fmaps = 12\n",
        "\n",
        "ds_fact = [(2,2),(2,2)]\n",
        "num_levels = len(ds_fact) + 1\n",
        "ksd = [[(3,3), (3,3)]]*num_levels\n",
        "ksu = [[(3,3), (3,3)]]*(num_levels - 1)\n",
        "\n",
        "# create unet\n",
        "unet = UNet(\n",
        "    in_channels=1,\n",
        "    num_fmaps=num_fmaps,\n",
        "    fmap_inc_factor=5,\n",
        "    downsample_factors=ds_fact,\n",
        "    kernel_size_down=ksd,\n",
        "    kernel_size_up=ksu,\n",
        "    constant_upsample=True)\n",
        "\n",
        "# add an extra convolution to get from 12 feature maps to 2 (affs in x,y)\n",
        "model = torch.nn.Sequential(\n",
        "    unet,\n",
        "    ConvPass(num_fmaps, 2, [[1, 1]], activation='Sigmoid'))\n",
        "\n",
        "# set loss and optimizer\n",
        "loss = WeightedMSELoss()\n",
        "optimizer = torch.optim.Adam(lr=0.5e-4, params=model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfvNBuIWQBIw"
      },
      "source": [
        "# Pre-cache repeated equal batch requests. subsequent requests can be served quickly.\n",
        "pipeline += gp.PreCache(num_workers=10)\n",
        "\n",
        "# add a train node\n",
        "pipeline += Train(\n",
        "    model,\n",
        "    loss,\n",
        "    optimizer,\n",
        "    inputs={\n",
        "        'input': raw\n",
        "    },\n",
        "    outputs={\n",
        "        0: pred_affs\n",
        "    },\n",
        "    loss_inputs={\n",
        "        0: pred_affs,\n",
        "        1: gt_affs,\n",
        "        2: affs_weights\n",
        "    })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka8z2kypQDl_"
      },
      "source": [
        "request = gp.BatchRequest()\n",
        "\n",
        "request.add(raw, input_size)\n",
        "request.add(labels, output_size)\n",
        "request.add(gt_affs, output_size)\n",
        "request.add(affs_weights, output_size)\n",
        "request.add(pred_affs, output_size)\n",
        "\n",
        "# train to ~1k iterations, view every 100th batch (1001 just to view last batch)\n",
        "iterations = 1001\n",
        "\n",
        "with gp.build(pipeline):\n",
        "    progress = tqdm(range(iterations))\n",
        "    for i in progress:\n",
        "        batch = pipeline.request_batch(request)\n",
        "\n",
        "        start = request[labels].roi.get_begin()/voxel_size\n",
        "        end = request[labels].roi.get_end()/voxel_size\n",
        "\n",
        "        if i % 100 == 0:\n",
        "\n",
        "          imshow(\n",
        "            raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]])\n",
        "          )\n",
        "          imshow(\n",
        "            ground_truth=batch[labels].data\n",
        "          )\n",
        "          imshow(\n",
        "            target=batch[gt_affs].data\n",
        "          )\n",
        "          imshow(\n",
        "            prediction=batch[pred_affs].data\n",
        "          )\n",
        "\n",
        "        progress.set_description(f'Training iteration {i}') \n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5J9JJoPK0K-"
      },
      "source": [
        "*  Just a general idea of how to use gunpowder - the networks in the paper are all in 3d and should be trained on sufficient hardware\n",
        "\n",
        "*  Results will probably vary since these are 2d slices of 3d data - sometimes more information is required in the z-dimension to inform predictions (especially for neuron segmentation). Feel free to try training for longer.\n",
        "\n",
        "*  see how to train lsds in **train_lsds.ipynb**"
      ]
    }
  ]
}