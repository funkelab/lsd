{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_mtlsd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxd06q3vZzlm"
      },
      "source": [
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This tutorial follows the lsds tutorial, and is therefore condensed. Check out the lsds tutorial (**train_lsds.ipynb**) if there is any confusion throughout\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  sometimes colab can be slow when training, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFzbgV1YZ2n0",
        "cellView": "form"
      },
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install mahotas\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install torch\n",
        "!pip install zarr\n",
        "\n",
        "# repos\n",
        "!pip install git+git://github.com/funkelab/daisy.git\n",
        "!pip install git+git://github.com/funkey/gunpowder.git\n",
        "!pip install git+git://github.com/funkelab/funlib.learn.torch.git\n",
        "!pip install git+git://github.com/funkelab/funlib.segment.git\n",
        "!pip install git+git://github.com/funkelab/lsd.git\n",
        "!pip install git+git://github.com/funkey/waterz.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UzsrNvAZ5LF",
        "cellView": "form"
      },
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from lsd.gp import AddLocalShapeDescriptor\n",
        "from gunpowder.torch import Train\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6exTbzR9Z_uV"
      },
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "# matplotlib uses a default shader\n",
        "# we need to recolor as unique objects\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint64)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al-0cyZlaC57",
        "cellView": "form"
      },
      "source": [
        "#@title utility  function to download / save data as zarr\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  f = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for i, r in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {r}')\n",
        "\n",
        "    raw_slice = raw[r:r+1,:,:]\n",
        "    labels_slice = labels[r:r+1,:,:]\n",
        "\n",
        "    if squeeze:\n",
        "      raw_slice = np.squeeze(raw_slice)\n",
        "      labels_slice = np.squeeze(labels_slice)\n",
        "\n",
        "    f[f'raw/{i}'] = raw_slice\n",
        "    f[f'labels/{i}'] = labels_slice\n",
        "\n",
        "    f[f'raw/{i}'].attrs['offset'] = offset\n",
        "    f[f'raw/{i}'].attrs['resolution'] = resolution\n",
        "\n",
        "    f[f'labels/{i}'].attrs['offset'] = offset\n",
        "    f[f'labels/{i}'].attrs['resolution'] = resolution"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7B9x2D7aG8Z",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view a batch\n",
        "\n",
        "# matplotlib.pyplot wrapper to view data\n",
        "# default shape should be 2 - 2d data\n",
        "\n",
        "def imshow(\n",
        "        raw=None,\n",
        "        ground_truth=None,\n",
        "        target=None,\n",
        "        prediction=None,\n",
        "        h=None,\n",
        "        shader='jet',\n",
        "        subplot=True,\n",
        "        channel=0,\n",
        "        target_name='target',\n",
        "        prediction_name='prediction'):\n",
        "\n",
        "    rows = 0\n",
        "\n",
        "    if raw is not None:\n",
        "        rows += 1\n",
        "        cols = raw.shape[0] if len(raw.shape) > 2 else 1\n",
        "    if ground_truth is not None:\n",
        "        rows += 1\n",
        "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 2 else 1\n",
        "    if target is not None:\n",
        "        rows += 1\n",
        "        cols = target.shape[0] if len(target.shape) > 2 else 1\n",
        "    if prediction is not None:\n",
        "        rows += 1\n",
        "        cols = prediction.shape[0] if len(prediction.shape) > 2 else 1\n",
        "\n",
        "    if subplot:\n",
        "        fig, axes = plt.subplots(\n",
        "            rows,\n",
        "            cols,\n",
        "            figsize=(10, 4),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "    if h is not None:\n",
        "        fig.subplots_adjust(hspace=h)\n",
        "\n",
        "    def wrapper(data,row,name=\"raw\"):\n",
        "\n",
        "        if subplot:\n",
        "            if len(data.shape) == 2:\n",
        "                if name == 'raw':\n",
        "                    axes[0][0].imshow(data, cmap='gray')\n",
        "                    axes[0][0].set_title(name)\n",
        "                else:\n",
        "                    axes[row][0].imshow(create_lut(data))\n",
        "                    axes[row][0].set_title(name)\n",
        "\n",
        "            elif len(data.shape) == 3:\n",
        "                for i, im in enumerate(data):\n",
        "                    if name == 'raw':\n",
        "                        axes[0][i].imshow(im, cmap='gray')\n",
        "                        axes[0][i].set_title(name)\n",
        "                    else:\n",
        "                        axes[row][i].imshow(create_lut(im))\n",
        "                        axes[row][i].set_title(name)\n",
        "\n",
        "            else:\n",
        "                for i, im in enumerate(data):\n",
        "                    axes[row][i].imshow(im[channel], cmap=shader)\n",
        "                    axes[row][i].set_title(name)\n",
        "\n",
        "\n",
        "        else:\n",
        "            if name == 'raw':\n",
        "                plt.imshow(data, cmap='gray')\n",
        "            if name == 'labels':\n",
        "                plt.imshow(data, alpha=0.5)\n",
        "\n",
        "    row=0 \n",
        "\n",
        "    if raw is not None:\n",
        "        wrapper(raw,row=row)\n",
        "        row += 1\n",
        "    if ground_truth is not None:\n",
        "        wrapper(ground_truth,row=row,name='labels')\n",
        "        row += 1\n",
        "    if target is not None:\n",
        "        wrapper(target,row=row,name=target_name)\n",
        "        row += 1\n",
        "    if prediction is not None:\n",
        "        wrapper(prediction,row=row,name=prediction_name)\n",
        "        row += 1\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiLtfH8NaLdm"
      },
      "source": [
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'training_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6efMx1KYq_A"
      },
      "source": [
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size\n",
        "\n",
        "num_fmaps=12\n",
        "num_samples=124\n",
        "batch_size=5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkxBq8BYchlf"
      },
      "source": [
        "# mtlsd model - designed to use lsds as an auxiliary learning task for improving affinities\n",
        "# raw --> lsds / affs\n",
        "\n",
        "# wrap model in a class. need two out heads, one for lsds, one for affs\n",
        "\n",
        "class MtlsdModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.unet = UNet(\n",
        "            in_channels=1,\n",
        "            num_fmaps=num_fmaps,\n",
        "            fmap_inc_factor=5,\n",
        "            downsample_factors=[\n",
        "                [2, 2],\n",
        "                [2, 2]],\n",
        "            kernel_size_down=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]],\n",
        "            kernel_size_up=[\n",
        "                [[3, 3], [3, 3]],\n",
        "                [[3, 3], [3, 3]]])\n",
        "\n",
        "        self.lsd_head = ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid')\n",
        "        self.aff_head = ConvPass(num_fmaps, 2, [[1, 1]], activation='Sigmoid')\n",
        "\n",
        "    def forward(self, input):\n",
        "\n",
        "        z = self.unet(input)\n",
        "        lsds = self.lsd_head(z)\n",
        "        affs = self.aff_head(z)\n",
        "\n",
        "        return lsds, affs\n",
        "\n",
        "# combine the lsds and affs losses\n",
        "\n",
        "class WeightedMSELoss(torch.nn.MSELoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(WeightedMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, lsds_prediction, lsds_target, lsds_weights, affs_prediction, affs_target, affs_weights,):\n",
        "\n",
        "        loss1 = super(WeightedMSELoss, self).forward(\n",
        "                lsds_prediction*lsds_weights,\n",
        "                lsds_target*lsds_weights)\n",
        "\n",
        "        loss2 = super(WeightedMSELoss, self).forward(\n",
        "            affs_prediction*affs_weights,\n",
        "            affs_target*affs_weights)\n",
        "        \n",
        "        return loss1 + loss2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3-HgKVaadEq"
      },
      "source": [
        "def train(\n",
        "    iterations,\n",
        "    show_every,\n",
        "    show_gt=True,\n",
        "    show_pred=False,\n",
        "    lsd_channels=None,\n",
        "    aff_channels=None):\n",
        "\n",
        "    raw = gp.ArrayKey('RAW')\n",
        "    labels = gp.ArrayKey('LABELS')\n",
        "    gt_lsds = gp.ArrayKey('GT_LSDS')\n",
        "    lsds_weights = gp.ArrayKey('LSDS_WEIGHTS')\n",
        "    pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
        "    gt_affs = gp.ArrayKey('GT_AFFS')\n",
        "    affs_weights = gp.ArrayKey('AFFS_WEIGHTS')\n",
        "    pred_affs = gp.ArrayKey('PRED_AFFS')\n",
        "\n",
        "    model = MtlsdModel()\n",
        "    loss = WeightedMSELoss()\n",
        "    optimizer = torch.optim.Adam(lr=0.5e-4, params=model.parameters())\n",
        "\n",
        "    request = gp.BatchRequest()\n",
        "    request.add(raw, input_size)\n",
        "    request.add(labels, output_size)\n",
        "    request.add(gt_lsds, output_size)\n",
        "    request.add(lsds_weights, output_size)\n",
        "    request.add(pred_lsds, output_size)\n",
        "    request.add(gt_affs, output_size)\n",
        "    request.add(affs_weights, output_size)\n",
        "    request.add(pred_affs, output_size)\n",
        "\n",
        "    sources = tuple(\n",
        "        gp.ZarrSource(\n",
        "            'training_data.zarr',  \n",
        "            {\n",
        "                raw: f'raw/{i}',\n",
        "                labels: f'labels/{i}'\n",
        "            },  \n",
        "            {\n",
        "                raw: gp.ArraySpec(interpolatable=True),\n",
        "                labels: gp.ArraySpec(interpolatable=False)\n",
        "            }) + \n",
        "            gp.Normalize(raw) +\n",
        "            gp.RandomLocation()\n",
        "            for i in range(num_samples)\n",
        "        )\n",
        "\n",
        "    # raw:      (h, w)\n",
        "    # labels:   (h, w)\n",
        "\n",
        "    pipeline = sources\n",
        "\n",
        "    pipeline += gp.RandomProvider()\n",
        "\n",
        "    pipeline += gp.SimpleAugment()\n",
        "\n",
        "    pipeline += gp.ElasticAugment(\n",
        "        control_point_spacing=(64, 64),\n",
        "        jitter_sigma=(5.0, 5.0),\n",
        "        rotation_interval=(0, math.pi/2))\n",
        "\n",
        "    pipeline += gp.IntensityAugment(\n",
        "        raw,\n",
        "        scale_min=0.9,\n",
        "        scale_max=1.1,\n",
        "        shift_min=-0.1,\n",
        "        shift_max=0.1)\n",
        "\n",
        "    pipeline += gp.GrowBoundary(labels)\n",
        "\n",
        "    pipeline += AddLocalShapeDescriptor(\n",
        "        labels,\n",
        "        gt_lsds,\n",
        "        mask=lsds_weights,\n",
        "        sigma=80,\n",
        "        downsample=1)\n",
        "        \n",
        "    pipeline += gp.AddAffinities(\n",
        "    affinity_neighborhood=[\n",
        "        [0, -1],\n",
        "        [-1, 0]],\n",
        "    labels=labels,\n",
        "    affinities=gt_affs,\n",
        "    dtype=np.float32)\n",
        "\n",
        "    pipeline += gp.BalanceLabels(\n",
        "        gt_affs,\n",
        "        affs_weights)\n",
        "\n",
        "    pipeline += gp.Unsqueeze([raw])\n",
        "\n",
        "    pipeline += gp.Stack(batch_size)\n",
        "\n",
        "    pipeline += gp.PreCache(num_workers=10)\n",
        "\n",
        "    pipeline += Train(\n",
        "        model,\n",
        "        loss,\n",
        "        optimizer,\n",
        "        inputs={\n",
        "            'input': raw\n",
        "        },\n",
        "        outputs={\n",
        "            0: pred_lsds,\n",
        "            1: pred_affs\n",
        "        },\n",
        "        loss_inputs={\n",
        "            0: pred_lsds,\n",
        "            1: gt_lsds,\n",
        "            2: lsds_weights,\n",
        "            3: pred_affs,\n",
        "            4: gt_affs,\n",
        "            5: affs_weights\n",
        "        })\n",
        "\n",
        "    with gp.build(pipeline):\n",
        "        for i in range(iterations):\n",
        "            batch = pipeline.request_batch(request)\n",
        "\n",
        "            start = request[labels].roi.get_begin()/voxel_size\n",
        "            end = request[labels].roi.get_end()/voxel_size\n",
        "\n",
        "            if i % show_every == 0:\n",
        "              \n",
        "              imshow(raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]))\n",
        "              imshow(ground_truth=batch[labels].data)\n",
        "\n",
        "              if lsd_channels:\n",
        "                for n,c in lsd_channels.items():\n",
        "                  \n",
        "                  if show_gt:\n",
        "                    imshow(target=batch[gt_lsds].data, target_name='gt '+n, channel=c)\n",
        "                  if show_pred:\n",
        "                    imshow(prediction=batch[pred_lsds].data, prediction_name='pred '+n, channel=c)\n",
        "\n",
        "              if aff_channels:\n",
        "                for n,c in aff_channels.items():\n",
        "\n",
        "                  if show_gt:\n",
        "                    imshow(target=batch[gt_affs].data, target_name='gt '+n, channel=c)\n",
        "                  if show_pred:\n",
        "                    imshow(target=batch[pred_affs].data, target_name='pred '+n, channel=c)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-5Awrb_dZmT"
      },
      "source": [
        "# view a batch of ground truth lsds/affs, no need to show predicted lsds/affs yet\n",
        "\n",
        "lsd_channels = {\n",
        "    'offset (y)': 0,\n",
        "    'offset (x)': 1,\n",
        "    'orient (y)': 2,\n",
        "    'orient (x)': 3,\n",
        "    'yx change': 4,\n",
        "    'voxel count': 5\n",
        "}\n",
        "\n",
        "#just view first y affs\n",
        "aff_channels = {'affs': 0}\n",
        "\n",
        "train(\n",
        "    iterations=1,\n",
        "    show_every=1,\n",
        "    lsd_channels=lsd_channels,\n",
        "    aff_channels=aff_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osWCdwcJdu4u"
      },
      "source": [
        "# lets just view the mean offset channels\n",
        "# train for 1k iterations, view every 100th batch\n",
        "# show the prediction as well as the ground truth\n",
        "\n",
        "lsd_channels = {\n",
        "    'offset (y)': 0,\n",
        "    'offset (x)': 1\n",
        "}\n",
        "\n",
        "aff_channels = {'affs': 0}\n",
        "\n",
        "train(\n",
        "    iterations=1000,\n",
        "    show_every=100,\n",
        "    show_pred=True,\n",
        "    lsd_channels=lsd_channels,\n",
        "    aff_channels=aff_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srpG9JSYbL7v"
      },
      "source": [
        "*  Just a general idea of how to use gunpowder - the networks in the paper are all in 3d and should be trained on sufficient hardware\n",
        "\n",
        "*  Results will probably vary since these are 2d slices of 3d data - sometimes more information is required in the z-dimension to inform predictions (especially for neuron segmentation). Feel free to try training for longer.\n",
        "\n",
        "*  see how to run inference in **inference.ipynb**"
      ]
    }
  ]
}