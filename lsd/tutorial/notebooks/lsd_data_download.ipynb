{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lsd_data_download.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj3oyx56AcYk"
      },
      "source": [
        "# LSD data overview\n",
        "\n",
        "###Overview:\n",
        "  * most data is stored as downloadable files/folders in an amazon s3 bucket\n",
        "  * some data is stored in a precomputed format inside a google bucket\n",
        "  * the s3 bucket contains about 1.7 tb of data, so bear in mind before downloading the whole bucket\n",
        "  * boto3 is a python api useful for accessing s3 data, you can use it to find sizes of folders before committing to downloading a directory (here is an example https://stackoverflow.com/questions/49759940/how-to-find-size-of-a-folder-inside-an-s3-bucket), and there are examples for downloading some data below (links at bottom of cell)\n",
        "  * s3 bucket contains a mixture of zarr, n5, nml, json, bson\n",
        "  * google bucket volume metadata is stored in info files. zarr/n5 metadata is stored in attributes files. To see offsets/shapes of cropped data (i.e hemi roi 1) check these files. \n",
        "  * google bucket volumes are in xyz voxel space.\n",
        "  * zarr volumes are in zyx world space (i.e nanometers)\n",
        "  * n5 volumes are in xyz world space\n",
        "\n",
        "---\n",
        "\n",
        "###Key: \n",
        "  * s3 = amazon s3 bucket\n",
        "  * gb = google bucket\n",
        "\n",
        "---\n",
        "\n",
        "###Storage structure:\n",
        "\n",
        "* Zebrafinch (**s3 and gb**) [view raw data](https://neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B9e-9%2C%22m%22%5D%2C%22y%22:%5B9e-9%2C%22m%22%5D%2C%22z%22:%5B2e-8%2C%22m%22%5D%7D%2C%22position%22:%5B5500.7841796875%2C5398.7626953125%2C2948.97021484375%5D%2C%22crossSectionScale%22:28.722131709470613%2C%22projectionOrientation%22:%5B-0.17645424604415894%2C-0.3241989314556122%2C-0.0025745832826942205%2C0.9293827414512634%5D%2C%22projectionScale%22:18561.198026865284%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://j0126-nature-methods-data/GgwKmcKgrcoNxJccKuGIzRnQqfit9hnfK1ctZzNbnuU/rawdata_realigned%22%2C%22tab%22:%22annotations%22%2C%22annotationColor%22:%22#0091ff%22%2C%22name%22:%22rawdata_realigned%22%7D%5D%2C%22selectedLayer%22:%7B%22layer%22:%22rawdata_realigned%22%7D%2C%22layout%22:%224panel%22%7D)\n",
        "\n",
        "  * training (**s3**)\n",
        "    * 33 **zarrs** with raw and label data\n",
        "\n",
        "  * testing\n",
        "    * raw (**gb-precomputed**)\n",
        "    * neuropil mask (**s3-zarr**)\n",
        "    * ground truth (**s3**)\n",
        "      * testing (**50 skeletons**)\n",
        "          * original (two versions - **nml** & **json**)\n",
        "          * consolidated (cropped, masked, relabelled connected components) (**bson**)\n",
        "            * nodes (total raw roi)\n",
        "            * edges (total raw roi)\n",
        "            * masks for each sub roi\n",
        "            * connected components for each sub roi\n",
        "      * validation (**12 skeletons**)\n",
        "        * original (**nml**)\n",
        "        * consolidated (**bson**)\n",
        "          * same structure as validation\n",
        "\n",
        "    * segmentations\n",
        "      * full ffn seg (**gb-precomputed**) (total raw roi)\n",
        "      * arrays (**s3-zarr-volumes**)\n",
        "        * supervoxels for each affinity-based network on the benchmark roi\n",
        "        * cropped/masked/relabelled ffn segmentation for each sub roi\n",
        "      * graphs (**s3-zarr-rags**)\n",
        "        * rags (region adjacency graphs) for each affinity-based network on benchmark roi (**bson**)\n",
        "          * nodes\n",
        "          * edges\n",
        "\n",
        "* Hemi-Brain (**s3**) [view raw data](https://neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B8e-9%2C%22m%22%5D%2C%22y%22:%5B8e-9%2C%22m%22%5D%2C%22z%22:%5B8e-9%2C%22m%22%5D%7D%2C%22position%22:%5B17137.673828125%2C20718.560546875%2C19731.599609375%5D%2C%22crossSectionScale%22:109.75827448209598%2C%22projectionOrientation%22:%5B-0.1407826691865921%2C-0.3292594850063324%2C0.0014168535126373172%2C0.9336843490600586%5D%2C%22projectionScale%22:65536%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://neuroglancer-janelia-flyem-hemibrain/emdata/clahe_yz/jpeg%22%2C%22tab%22:%22source%22%2C%22annotationColor%22:%22#00aaff%22%2C%22name%22:%22raw%22%7D%5D%2C%22selectedLayer%22:%7B%22layer%22:%22raw%22%7D%2C%22layout%22:%224panel%22%7D)\n",
        "\n",
        "  * training\n",
        "    * 8 **zarrs** with raw and label data\n",
        "\n",
        "  * testing\n",
        "    * ground truth (**s3-zarr-volumes**)\n",
        "      * EB mask\n",
        "      * three rois\n",
        "        * raw\n",
        "        * labels (dense, cropped to roi)\n",
        "        * consolidated labels (filtered, masked to neuropil, eroded boundaries, relabelled connected components)\n",
        "    * segmentations\n",
        "      * arrays (**s3-zarr-volumes**)\n",
        "        * supervoxels for each affinity-based network on 3 rois\n",
        "        * ffn segmentation for each sub roi\n",
        "        * cropped/masked/relabelled ffn segmentation for each sub roi\n",
        "      * graphs (**s3-zarr-rags**)\n",
        "        * rags (region adjacency graphs) for each affinity-based network on sub rois (**bson**)\n",
        "\n",
        "\n",
        "* FIB-25 (**s3**) [view raw data](https://neuroglancer-demo.appspot.com/#!%7B%22dimensions%22:%7B%22x%22:%5B8e-9%2C%22m%22%5D%2C%22y%22:%5B8e-9%2C%22m%22%5D%2C%22z%22:%5B8e-9%2C%22m%22%5D%7D%2C%22position%22:%5B3326.20947265625%2C3379.239013671875%2C4060.844482421875%5D%2C%22crossSectionScale%22:19.54375528952488%2C%22projectionOrientation%22:%5B-0.21999090909957886%2C-0.4366961419582367%2C-0.12671823799610138%2C0.8630428314208984%5D%2C%22projectionScale%22:15850.514470059576%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22precomputed://gs://neuroglancer-public-data/flyem_fib-25/image%22%2C%22tab%22:%22annotations%22%2C%22annotationColor%22:%22#009dff%22%2C%22name%22:%22raw%22%7D%5D%2C%22selectedLayer%22:%7B%22layer%22:%22raw%22%7D%2C%22layout%22:%224panel%22%7D)\n",
        "\n",
        "  * training\n",
        "      * 4 **zarrs** with raw and label data\n",
        "\n",
        "    * testing\n",
        "      * ground truth (**s3-n5**)\n",
        "        * raw\n",
        "        * neuropil mask\n",
        "        * labels\n",
        "        * cropped/relabelled ids for two subrois\n",
        "      * segmentations\n",
        "        * arrays (**s3-zarr-volumes**)\n",
        "          * supervoxels for each affinity-based network\n",
        "          * full ffn segmentation\n",
        "          * cropped/relabelled ffn segmentation for two subrois\n",
        "        * graphs (**s3-zarr-rags**)\n",
        "          * rags (region adjacency graphs) for each affinity-based network on full roi (**bson**)\n",
        "\n",
        "---\n",
        "\n",
        "###Examples:\n",
        "\n",
        "**make sure to install / import packages in the next two cells first**\n",
        "\n",
        "- [fetch/view from google bucket](#fetch-gb)\n",
        "- [connect to s3 bucket](#s3-connect)\n",
        "- [fetch/view s3 array data](#s3-array)\n",
        "- [fetch/view s3 graph data](#s3-graph)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2O8isY0fFAJ"
      },
      "source": [
        "!pip install boto3\n",
        "!pip install cloud-volume\n",
        "!pip install matplotlib\n",
        "\n",
        "# C header error bc of cloud-volume? have to specify numpy version...\n",
        "!pip install numpy==1.20.0\n",
        "\n",
        "!pip install pandas\n",
        "!pip install plotly\n",
        "!pip install requests\n",
        "!pip install scikit-image\n",
        "!pip install zarr\n",
        "\n",
        "# since colab has its own versions pre-installed but we\n",
        "# need some other versions, the runtime needs to be restarted\n",
        "# there will be warnings, but the runtime restart should resolve.\n",
        "# just hit the x on the popup that comes up in bottom left corner\n",
        "# then run following cells\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7grcrVufkRw"
      },
      "source": [
        "import boto3\n",
        "import bson\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import zarr\n",
        "from cloudvolume import CloudVolume"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtoL6wEx1dPv"
      },
      "source": [
        "<a name=\"fetch-gb\"></a>\n",
        "# fetch/view google bucket data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahzJzM2OBuSU"
      },
      "source": [
        "raw_vol = CloudVolume(\n",
        "            \"https://storage.googleapis.com/j0126-nature-methods-data/GgwKmcKgrcoNxJccKuGIzRnQqfit9hnfK1ctZzNbnuU/rawdata_realigned\",\n",
        "            bounded=True,\n",
        "            progress=True)\n",
        "\n",
        "seg_vol = CloudVolume(\n",
        "            \"https://storage.googleapis.com/j0126-nature-methods-data/GgwKmcKgrcoNxJccKuGIzRnQqfit9hnfK1ctZzNbnuU/ffn_segmentation\",\n",
        "            bounded=True,\n",
        "            progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLpebg_RBxqU"
      },
      "source": [
        "# cloud data shape is stored as x,y,z,channel\n",
        "print(raw_vol.shape, seg_vol.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ByiFVMph5U"
      },
      "source": [
        "# view metadata\n",
        "seg_vol.info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSg3j1tW_3yY"
      },
      "source": [
        "# function to slice cloud volume, convert to 2d numpy array for viewing\n",
        "def cloud_to_np(vol,x0,x1,y0,y1,z0,z1):\n",
        "\n",
        "  # ensure there is a voxel offset in the metadata so cloudvolume is happy\n",
        "  for scale in vol.info['scales']:\n",
        "        scale['voxel_offset'] = [0, 0, 0]\n",
        "  \n",
        "  # slice data\n",
        "  data = vol[x0:x1, y0:y1, z0:z1]\n",
        "\n",
        "  # transpose (z,y,x)\n",
        "  data = np.transpose(data[...,0], [2,1,0])\n",
        "\n",
        "  # remove z dim so we can view as 2d image\n",
        "  return np.squeeze(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IztUw3U1-56_"
      },
      "source": [
        "# get a random 1000x1000 voxel patch \n",
        "raw_data = cloud_to_np(raw_vol,1000,2000,2000,3000,300,301)\n",
        "seg_data = cloud_to_np(seg_vol,1000,2000,2000,3000,300,301)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ8Ewmc3CB3x"
      },
      "source": [
        "# utility function for viewing unique labels\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint64)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDpWRBaP9IaR"
      },
      "source": [
        "# view the data\n",
        "plt.imshow(raw_data, cmap='gray')\n",
        "plt.imshow(create_lut(seg_data), alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sQr0LuL1mXl"
      },
      "source": [
        "<a name=\"s3-connect\"></a>\n",
        "# connect to s3 bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDL38VnxhI6T"
      },
      "source": [
        "# set bucket credentials\n",
        "access_key = 'AKIA4XXGEV6ZQOTMTHX6'\n",
        "secret_key = '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'\n",
        "bucket = 'open-neurodata'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2gTfGEvgLr0"
      },
      "source": [
        "# connect to client\n",
        "client = boto3.client('s3', aws_access_key_id=access_key, aws_secret_access_key=secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVGfxKT2i3MX"
      },
      "source": [
        "# list data\n",
        "client.list_objects(Bucket=bucket, Prefix=\"funke\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9WmDV1QhXlZ"
      },
      "source": [
        "# download directory structure file - this shows exactly how the s3 data is stored\n",
        "client.download_file(\n",
        "    Bucket=bucket,\n",
        "    Key=\"funke/structure.md\",\n",
        "    Filename=\"structure.md\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOiVIDoAhEHm"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBPlP4VPguue"
      },
      "source": [
        "less structure.md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mNwx_q22l-o"
      },
      "source": [
        "<a name=\"s3-array\"></a>\n",
        "# fetch/view s3 array data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0Z82whnfsiB"
      },
      "source": [
        "# function to download all files nested in a bucket path\n",
        "def downloadDirectory(\n",
        "    bucket_name,\n",
        "    path,\n",
        "    access_key,\n",
        "    secret_key):\n",
        "  \n",
        "    resource = boto3.resource(\n",
        "        's3',\n",
        "        aws_access_key_id=access_key,\n",
        "        aws_secret_access_key=secret_key)\n",
        "    \n",
        "    bucket = resource.Bucket(bucket_name)\n",
        "\n",
        "    for obj in bucket.objects.filter(Prefix=path):\n",
        "        if not os.path.exists(os.path.dirname(obj.key)):\n",
        "            os.makedirs(os.path.dirname(obj.key))\n",
        "        \n",
        "        key = obj.key\n",
        "\n",
        "        print(f'Downloading {key}')\n",
        "        bucket.download_file(key, key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE-dcmiTimOm"
      },
      "source": [
        "# download example fib25 training data\n",
        "downloadDirectory(\n",
        "    bucket,\n",
        "    'funke/fib25/training/trvol-250-1.zarr',\n",
        "    access_key,\n",
        "    secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_62HIsdi6cg"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb7-CZ9xkWBU"
      },
      "source": [
        "ls funke/fib25/training/trvol-250-1.zarr/volumes/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_LyW_ofkd2G"
      },
      "source": [
        "# load zarr file\n",
        "f = zarr.open('funke/fib25/training/trvol-250-1.zarr')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dclS4JElFVO"
      },
      "source": [
        "# load data into numpy arrays\n",
        "raw = f['volumes/raw'][:]\n",
        "labels = f['volumes/labels/neuron_ids'][:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzXqYD-loAW1"
      },
      "source": [
        "# view offset, resolution (z,y,x)\n",
        "print(f['volumes/raw'].attrs['offset'])\n",
        "print(f['volumes/raw'].attrs['resolution'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J42jsBkRlHk2"
      },
      "source": [
        "# view raw data\n",
        "raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWsSXdCCnsX9"
      },
      "source": [
        "# view shapes (voxels)\n",
        "print(raw.shape, labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNE0_lMglIGU"
      },
      "source": [
        "# slice first section, squeeze z axis for viewing in matplotlib\n",
        "raw_0 = np.squeeze(raw[0:1, :, :])\n",
        "labels_0 = np.squeeze(labels[0:1, :, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuLz-Qj5lf6P"
      },
      "source": [
        "# show data\n",
        "plt.imshow(raw_0, cmap='gray')\n",
        "plt.imshow(create_lut(labels_0), alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1y1jaVb2XlR"
      },
      "source": [
        "<a name=\"s3-graph\"></a>\n",
        "# fetch/view s3 graph data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGpK1bNqD-u"
      },
      "source": [
        "# download example hemi region adjacency graph\n",
        "downloadDirectory(\n",
        "    bucket,\n",
        "    'funke/hemi/testing/segmentations/data.zarr/rags/ACLSD/hemi_affs_from_lsd_200k_roi_1',\n",
        "    access_key,\n",
        "    secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK9XHs6IrGOq"
      },
      "source": [
        "ls funke/hemi/testing/segmentations/data.zarr/rags/ACLSD/hemi_affs_from_lsd_200k_roi_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-YDVEPeLuwj"
      },
      "source": [
        "# function to create pandas dataframe from bson data\n",
        "def create_df(bson_file):\n",
        "\n",
        "  with open(bson_file, 'rb') as f:\n",
        "    data = bson.decode_all(f.read())\n",
        "\n",
        "  df = pd.DataFrame(data)\n",
        "  del df['_id']\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEDXjV3nMLZW"
      },
      "source": [
        "# create nodes dataframe\n",
        "nodes = create_df('funke/hemi/testing/segmentations/data.zarr/rags/ACLSD/hemi_affs_from_lsd_200k_roi_1/nodes.bson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LytB7fBnynhm"
      },
      "source": [
        "# view nodes - coordinates are in world units, divide by voxel size (8,8,8)\n",
        "# to see voxel space\n",
        "nodes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ4G1wiyCrmh"
      },
      "source": [
        "# randomly sample some points\n",
        "sample = nodes.sample(10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh8M4dSUCx0X"
      },
      "source": [
        "# view nodes - color mapping allows us to see block boundaries, since\n",
        "# unique node ids are incremented spatially with respect to a block.\n",
        "# the non-uniform cube is due to masking an axon tract along the edge\n",
        "fig = px.scatter_3d(\n",
        "    sample,\n",
        "    x='center_x',\n",
        "    y='center_y',\n",
        "    z='center_z',\n",
        "    color='id',\n",
        "    color_continuous_scale=px.colors.sequential.Jet)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrn1E7pgBX0n"
      },
      "source": [
        "# get the edges\n",
        "edges = create_df('funke/hemi/testing/segmentations/data.zarr/rags/ACLSD/hemi_affs_from_lsd_200k_roi_1/edges_hist_quant_75.bson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84oXVJXSBdaO"
      },
      "source": [
        "# the edges map between nodes (u=source, v=target) and have a merge score\n",
        "# based on underlying affinity values. this merge score determines when the nodes\n",
        "# would become merged (edges with lower scores are merged earlier)\n",
        "edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDwJkHEcsGNn"
      },
      "source": [
        "# find first edge source location\n",
        "nodes.loc[nodes['id'] == 77322656252]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPQ3z0nh0QL6"
      },
      "source": [
        "# download example zebrafinch validation skeletons\n",
        "downloadDirectory(\n",
        "    bucket,\n",
        "    'funke/zebrafinch/testing/ground_truth/validation/consolidated/zebrafinch_gt_skeletons_new_gt_9_9_20_validation',\n",
        "    access_key,\n",
        "    secret_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h52bPSWz0rua"
      },
      "source": [
        "# get the validation skeleton nodes\n",
        "val_nodes = create_df('funke/zebrafinch/testing/ground_truth/validation/consolidated/zebrafinch_gt_skeletons_new_gt_9_9_20_validation/zebrafinch.nodes.bson')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41KN665UrcBX"
      },
      "source": [
        "# sample the nodes\n",
        "val_nodes_sample = val_nodes.sample(20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gBVyEHfqrXj"
      },
      "source": [
        "# default zoomed in camera\n",
        "camera = dict(\n",
        "    eye=dict(x=0.2, y=0.2, z=0.2)\n",
        ")\n",
        "\n",
        "# color by neuron id\n",
        "fig = px.scatter_3d(\n",
        "    val_nodes_sample,\n",
        "    x='x',\n",
        "    y='y',\n",
        "    z='z',\n",
        "    color='neuron_id',\n",
        "    color_continuous_scale=px.colors.sequential.Jet)\n",
        "fig.update_layout(scene_camera=camera)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb1VWsHvvUg9"
      },
      "source": [
        "# check unique neurons\n",
        "print(val_nodes['neuron_id'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_OTnHf06cR"
      },
      "source": [
        "# view an example neuron\n",
        "val_nodes_single = val_nodes.loc[val_nodes['neuron_id']==1]\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    val_nodes_single,\n",
        "    x='x',\n",
        "    y='y',\n",
        "    z='z')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
