{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_lsds.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_Z2BLGXFOYK"
      },
      "source": [
        "*  Before starting, click \"Runtime\" in the top panel, select \"Change runtime type\" and then choose \"GPU\"\n",
        "\n",
        "*  This tutorial follows the affinities tutorial, and is therefore condensed. Check out the affinities tutorial (**train_affinities.ipynb**) if there is any confusion throughout\n",
        "\n",
        "*  Try running each cell consecutively to see what is happening before changing things around\n",
        "\n",
        "*  Some cells are collapsed by default, these are generally utility functions or are expanded by defaullt in a previous tutorial. Double click to expand/collapse\n",
        "\n",
        "*  Sometimes colab can be slow when training, if this happens you may need to restart the runtime. also, you generally can only run one session at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5GiR_E2yrzE",
        "cellView": "form"
      },
      "source": [
        "#@title install packages + repos\n",
        "\n",
        "# packages\n",
        "!pip install gunpowder\n",
        "!pip install matplotlib\n",
        "!pip install scikit-image\n",
        "!pip install torch\n",
        "!pip install zarr\n",
        "\n",
        "# repos\n",
        "!pip install git+https://github.com/funkelab/funlib.learn.torch.git\n",
        "!pip install git+https://github.com/funkelab/lsd.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDeVQ0Y0zCJ0",
        "cellView": "form"
      },
      "source": [
        "#@title import packages\n",
        "\n",
        "import gunpowder as gp\n",
        "import h5py\n",
        "import io\n",
        "import logging\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import requests\n",
        "import torch\n",
        "import zarr\n",
        "\n",
        "from funlib.learn.torch.models import UNet, ConvPass\n",
        "from gunpowder.torch import Train\n",
        "from lsd.train.gp import AddLocalShapeDescriptor\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "vjuG-1yKzN8t"
      },
      "source": [
        "#@title utility function to view labels\n",
        "\n",
        "# matplotlib uses a default shader\n",
        "# we need to recolor as unique objects\n",
        "\n",
        "def create_lut(labels):\n",
        "\n",
        "    max_label = np.max(labels)\n",
        "\n",
        "    lut = np.random.randint(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            size=(int(max_label + 1), 3),\n",
        "            dtype=np.uint8)\n",
        "\n",
        "    lut = np.append(\n",
        "            lut,\n",
        "            np.zeros(\n",
        "                (int(max_label + 1), 1),\n",
        "                dtype=np.uint8) + 255,\n",
        "            axis=1)\n",
        "\n",
        "    lut[0] = 0\n",
        "    colored_labels = lut[labels]\n",
        "\n",
        "    return colored_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uzHBfSA1doo",
        "cellView": "form"
      },
      "source": [
        "#@title utility  function to download / save data as zarr\n",
        "\n",
        "def create_data(\n",
        "    url, \n",
        "    name, \n",
        "    offset, \n",
        "    resolution,\n",
        "    sections=None,\n",
        "    squeeze=True):\n",
        "\n",
        "  in_f = h5py.File(io.BytesIO(requests.get(url).content), 'r')\n",
        "\n",
        "  raw = in_f['volumes/raw']\n",
        "  labels = in_f['volumes/labels/neuron_ids']\n",
        "  \n",
        "  container = zarr.open(name, 'a')\n",
        "\n",
        "  if sections is None:\n",
        "    sections=range(raw.shape[0]-1)\n",
        "\n",
        "  for index, section in enumerate(sections):\n",
        "\n",
        "    print(f'Writing data for section {section}')\n",
        "\n",
        "    raw_slice = raw[section]\n",
        "    labels_slice = labels[section]\n",
        "\n",
        "    if squeeze:\n",
        "      raw_slice = np.squeeze(raw_slice)\n",
        "      labels_slice = np.squeeze(labels_slice)\n",
        "\n",
        "    for ds_name, data in [\n",
        "        ('raw', raw_slice),\n",
        "        ('labels', labels_slice)]:\n",
        "        \n",
        "        container[f'{ds_name}/{index}'] = data\n",
        "        container[f'{ds_name}/{index}'].attrs['offset'] = offset\n",
        "        container[f'{ds_name}/{index}'].attrs['resolution'] = resolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMuWw-Ck1jfF",
        "cellView": "form"
      },
      "source": [
        "#@title utility function to view a batch\n",
        "\n",
        "# matplotlib.pyplot wrapper to view data\n",
        "# default shape should be 2 - 2d data\n",
        "\n",
        "def imshow(\n",
        "        raw=None,\n",
        "        ground_truth=None,\n",
        "        target=None,\n",
        "        prediction=None,\n",
        "        h=None,\n",
        "        shader='jet',\n",
        "        subplot=True,\n",
        "        channel=0,\n",
        "        target_name='target',\n",
        "        prediction_name='prediction'):\n",
        "\n",
        "    rows = 0\n",
        "\n",
        "    if raw is not None:\n",
        "        rows += 1\n",
        "        cols = raw.shape[0] if len(raw.shape) > 2 else 1\n",
        "    if ground_truth is not None:\n",
        "        rows += 1\n",
        "        cols = ground_truth.shape[0] if len(ground_truth.shape) > 2 else 1\n",
        "    if target is not None:\n",
        "        rows += 1\n",
        "        cols = target.shape[0] if len(target.shape) > 2 else 1\n",
        "    if prediction is not None:\n",
        "        rows += 1\n",
        "        cols = prediction.shape[0] if len(prediction.shape) > 2 else 1\n",
        "\n",
        "    if subplot:\n",
        "        fig, axes = plt.subplots(\n",
        "            rows,\n",
        "            cols,\n",
        "            figsize=(10, 4),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "    if h is not None:\n",
        "        fig.subplots_adjust(hspace=h)\n",
        "\n",
        "    def wrapper(data,row,name=\"raw\"):\n",
        "\n",
        "        if subplot:\n",
        "            if len(data.shape) == 2:\n",
        "                if name == 'raw':\n",
        "                    axes[0][0].imshow(data, cmap='gray')\n",
        "                    axes[0][0].set_title(name)\n",
        "                else:\n",
        "                    axes[row][0].imshow(create_lut(data))\n",
        "                    axes[row][0].set_title(name)\n",
        "\n",
        "            elif len(data.shape) == 3:\n",
        "                for i, im in enumerate(data):\n",
        "                    if name == 'raw':\n",
        "                        axes[0][i].imshow(im, cmap='gray')\n",
        "                        axes[0][i].set_title(name)\n",
        "                    else:\n",
        "                        axes[row][i].imshow(create_lut(im))\n",
        "                        axes[row][i].set_title(name)\n",
        "\n",
        "            else:\n",
        "                for i, im in enumerate(data):\n",
        "                    axes[row][i].imshow(im[channel], cmap=shader)\n",
        "                    axes[row][i].set_title(name)\n",
        "\n",
        "\n",
        "        else:\n",
        "            if name == 'raw':\n",
        "                plt.imshow(data, cmap='gray')\n",
        "            if name == 'labels':\n",
        "                plt.imshow(data, alpha=0.5)\n",
        "\n",
        "    row=0 \n",
        "\n",
        "    if raw is not None:\n",
        "        wrapper(raw,row=row)\n",
        "        row += 1\n",
        "    if ground_truth is not None:\n",
        "        wrapper(ground_truth,row=row,name='labels')\n",
        "        row += 1\n",
        "    if target is not None:\n",
        "        wrapper(target,row=row,name=target_name)\n",
        "        row += 1\n",
        "    if prediction is not None:\n",
        "        wrapper(prediction,row=row,name=prediction_name)\n",
        "        row += 1\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRjBINJJOPKb"
      },
      "source": [
        "create_data(\n",
        "    'https://cremi.org/static/data/sample_A_20160501.hdf',\n",
        "    'training_data.zarr',\n",
        "    offset=[0,0],\n",
        "    resolution=[4,4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbpOuX4k19TA"
      },
      "source": [
        "voxel_size = gp.Coordinate((4, 4))\n",
        "\n",
        "input_shape = gp.Coordinate((164, 164))\n",
        "output_shape = gp.Coordinate((124, 124))\n",
        "\n",
        "input_size = input_shape * voxel_size\n",
        "output_size = output_shape * voxel_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLc1FOAi2Aqc"
      },
      "source": [
        "# weighted mean squared error loss\n",
        "\n",
        "class WeightedMSELoss(torch.nn.MSELoss):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(WeightedMSELoss, self).__init__()\n",
        "\n",
        "    def forward(self, prediction, target, weights):\n",
        "\n",
        "        scaled = (weights * (prediction - target) ** 2)\n",
        "\n",
        "        if len(torch.nonzero(scaled)) != 0:\n",
        "\n",
        "            mask = torch.masked_select(scaled, torch.gt(weights, 0))\n",
        "            loss = torch.mean(mask)\n",
        "\n",
        "        else:\n",
        "            loss = torch.mean(scaled)\n",
        "\n",
        "        return loss\n",
        "        \n",
        "# here we'll wrap our pipeline in a function to make it easy to call in subsequent cells\n",
        "\n",
        "def train(\n",
        "    iterations,\n",
        "    batch_size,\n",
        "    show_every,\n",
        "    show_gt=True,\n",
        "    show_pred=False,\n",
        "    channels={'offset in y': 0}):\n",
        "    \n",
        "    raw = gp.ArrayKey('RAW')\n",
        "    labels = gp.ArrayKey('LABELS')\n",
        "    gt_lsds = gp.ArrayKey('GT_LSDS')\n",
        "    lsds_weights = gp.ArrayKey('LSDS_WEIGHTS')\n",
        "    pred_lsds = gp.ArrayKey('PRED_LSDS')\n",
        "    \n",
        "    request = gp.BatchRequest()\n",
        "\n",
        "    request.add(raw, input_size)\n",
        "    request.add(labels, output_size)\n",
        "    request.add(gt_lsds, output_size)\n",
        "    request.add(lsds_weights, output_size)\n",
        "    request.add(pred_lsds, output_size)\n",
        "\n",
        "    num_samples = 124\n",
        "    num_fmaps = 12\n",
        "    \n",
        "    ds_fact = [(2,2),(2,2)]\n",
        "    num_levels = len(ds_fact) + 1\n",
        "    ksd = [[(3,3), (3,3)]]*num_levels\n",
        "    ksu = [[(3,3), (3,3)]]*(num_levels - 1)\n",
        "\n",
        "    # create unet\n",
        "    unet = UNet(\n",
        "      in_channels=1,\n",
        "      num_fmaps=num_fmaps,\n",
        "      fmap_inc_factor=5,\n",
        "      downsample_factors=ds_fact,\n",
        "      kernel_size_down=ksd,\n",
        "      kernel_size_up=ksu,\n",
        "      constant_upsample=True)\n",
        "\n",
        "    # need 6 output channels (lsd on 2d data is 6 dimensional)\n",
        "    # LSD[0:1] = mean offset in y\n",
        "    # LSD[1:2] = mean offset in x\n",
        "    # LSD[2:3] = orientation in y\n",
        "    # LSD[3:4] = orientation in x\n",
        "    # LSD[4:5] = change in orientation y-x\n",
        "    # LSD[5:6] = size (voxel count)\n",
        "\n",
        "    model = torch.nn.Sequential(\n",
        "        unet,\n",
        "        ConvPass(num_fmaps, 6, [[1, 1]], activation='Sigmoid'))\n",
        "\n",
        "    loss = WeightedMSELoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(lr=0.5e-4, params=model.parameters())\n",
        "\n",
        "    sources = tuple(\n",
        "        gp.ZarrSource(\n",
        "            'training_data.zarr',  \n",
        "            {\n",
        "                raw: f'raw/{i}',\n",
        "                labels: f'labels/{i}'\n",
        "            },  \n",
        "            {\n",
        "                raw: gp.ArraySpec(interpolatable=True),\n",
        "                labels: gp.ArraySpec(interpolatable=False)\n",
        "            }) + \n",
        "            gp.Normalize(raw) +\n",
        "            gp.RandomLocation()\n",
        "            for i in range(num_samples)\n",
        "        )\n",
        "\n",
        "    # raw: (h, w)\n",
        "    # labels: (h, w)\n",
        "\n",
        "    pipeline = sources\n",
        "\n",
        "    pipeline += gp.RandomProvider()\n",
        "\n",
        "    pipeline += gp.SimpleAugment()\n",
        "\n",
        "    pipeline += gp.IntensityAugment(\n",
        "        raw,\n",
        "        scale_min=0.9,\n",
        "        scale_max=1.1,\n",
        "        shift_min=-0.1,\n",
        "        shift_max=0.1)\n",
        "\n",
        "    pipeline += gp.GrowBoundary(labels)\n",
        "\n",
        "    # calculate lsds on labels.\n",
        "    pipeline += AddLocalShapeDescriptor(\n",
        "        labels,\n",
        "        gt_lsds,\n",
        "        lsds_mask=lsds_weights,\n",
        "        sigma=80,\n",
        "        downsample=2)\n",
        "\n",
        "    # raw: (h, w)\n",
        "    # labels: (h, w)\n",
        "    # gt_lsds: (6, h, w)\n",
        "\n",
        "    # add \"channel\" dimensions\n",
        "    pipeline += gp.Unsqueeze([raw])\n",
        "\n",
        "    # raw: (1, h, w)\n",
        "    # gt_lsds: (6, h, w)\n",
        "    # lsds weights: (6, h, w)\n",
        "\n",
        "    pipeline += gp.Stack(batch_size)\n",
        "\n",
        "    # raw: (b, 1, h, w)\n",
        "    # gt_lsds: (b, 6, h, w)\n",
        "    # lsds weights: (b, 6, h, w)\n",
        "    \n",
        "    pipeline += gp.PreCache(num_workers=10)\n",
        "\n",
        "    pipeline += Train(\n",
        "        model,\n",
        "        loss,\n",
        "        optimizer,\n",
        "        inputs={\n",
        "            'input': raw\n",
        "        },\n",
        "        outputs={\n",
        "            0: pred_lsds\n",
        "        },\n",
        "        loss_inputs={\n",
        "            0: pred_lsds,\n",
        "            1: gt_lsds,\n",
        "            2: lsds_weights\n",
        "        })\n",
        "    \n",
        "    with gp.build(pipeline):\n",
        "        progress = tqdm(range(iterations))\n",
        "        for i in progress:\n",
        "            batch = pipeline.request_batch(request)\n",
        "\n",
        "            start = request[labels].roi.get_begin()/voxel_size\n",
        "            end = request[labels].roi.get_end()/voxel_size\n",
        "\n",
        "            if i % show_every == 0:\n",
        "              \n",
        "              imshow(raw=np.squeeze(batch[raw].data[:,:,start[0]:end[0],start[1]:end[1]]))\n",
        "              imshow(ground_truth=batch[labels].data)\n",
        "\n",
        "              for n,c in channels.items():\n",
        "                \n",
        "                if show_gt:\n",
        "                  imshow(target=batch[gt_lsds].data, target_name='gt '+n, channel=c)\n",
        "                if show_pred:\n",
        "                  imshow(prediction=batch[pred_lsds].data, prediction_name='pred '+n, channel=c)\n",
        "\n",
        "            progress.set_description(f'Training iteration {i}') \n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb92KP8U3S6v"
      },
      "source": [
        "# view a batch of ground truth lsds, no need to show predicted lsds yet\n",
        "\n",
        "channels = {\n",
        "    'offset (y)': 0,\n",
        "    'offset (x)': 1,\n",
        "    'orient (y)': 2,\n",
        "    'orient (x)': 3,\n",
        "    'yx change': 4,\n",
        "    'voxel count': 5\n",
        "}\n",
        "\n",
        "train(iterations=1, batch_size=5, show_every=1, channels=channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUmO0bONTGCv"
      },
      "source": [
        "# can also calculate lsds without gunpowder (just a numpy array)\n",
        "\n",
        "from lsd.train import local_shape_descriptor\n",
        "\n",
        "f = zarr.open('training_data.zarr')\n",
        "test_raw = f['raw/0'][:]\n",
        "test_labels = f['labels/0'][:]\n",
        "\n",
        "# just take the a 250x250 voxel patch from the corner\n",
        "test_raw = test_raw[0:250, 0:250]\n",
        "test_labels = test_labels[0:250, 0:250]\n",
        "\n",
        "plt.imshow(test_raw, cmap='gray')\n",
        "plt.imshow(create_lut(test_labels), alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2xBxKy0TXPm"
      },
      "source": [
        "# test different sigmas for growing the gaussian (want something that works well for all sized processes)\n",
        "# too small of a sigma decreases contrast at boundaries\n",
        "# too high of a sigma decreases the gradient across the object\n",
        "# in this case a sigma of 100 seems to be a good bet - the mean offset should make objects look 3d\n",
        "\n",
        "sigmas = [4, 50, 100, 200, 500]\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "            1,\n",
        "            5,\n",
        "            figsize=(20, 6),\n",
        "            sharex=True,\n",
        "            sharey=True,\n",
        "            squeeze=False)\n",
        "\n",
        "for i, sig in enumerate(sigmas):\n",
        "  \n",
        "  lsds = local_shape_descriptor.get_local_shape_descriptors(\n",
        "              segmentation=test_labels,\n",
        "              sigma=(sig,)*3,\n",
        "              voxel_size=voxel_size)\n",
        "  \n",
        "  # view mean offset component (x & y overlay)\n",
        "  axes[0][i].imshow(np.squeeze(lsds[0,:,:]), cmap='jet')\n",
        "  axes[0][i].imshow(np.squeeze(lsds[1,:,:]), cmap='jet', alpha=0.5)\n",
        "  axes[0][i].set_title(f'Sigma: {str(sig)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3J7S5Y6g-u"
      },
      "source": [
        "# train for ~1k iterations, view every 100th batch\n",
        "# lets just view the mean offset y channel\n",
        "# show the prediction as well as the ground truth\n",
        "# will take longer to converge than affs\n",
        "\n",
        "channels = {'offset (y)': 0}\n",
        "\n",
        "train(iterations=1001, batch_size=3, show_every=100, show_pred=True, channels=channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThD_rfu8XHfE"
      },
      "source": [
        "*  Just a general idea of how to use gunpowder - the networks in the paper are all in 3d and should be trained on sufficient hardware\n",
        "\n",
        "*  Results will probably vary since these are 2d slices of 3d data - sometimes more information is required in the z-dimension to inform predictions (especially for neuron segmentation). Feel free to try training for longer.\n",
        "\n",
        "*  The lsds can also be used in a pure pytorch or tensorflow pipeline (i.e without gunpowder) since they can be calculated as a numpy array on label data\n",
        "\n",
        "*  see how to train an mtlsd network (similar to network in paper) in  **train_mtlsd.ipynb**"
      ]
    }
  ]
}